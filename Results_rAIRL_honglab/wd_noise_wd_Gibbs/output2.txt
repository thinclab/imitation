WARNING - root - Added new config entry: "env_make_kwargs.cov_diag_val_act_noise"
WARNING - root - Added new config entry: "env_make_kwargs.cov_diag_val_st_noise"
WARNING - root - Added new config entry: "env_make_kwargs.cov_diag_val_transition_model"
WARNING - root - Added new config entry: "env_make_kwargs.full_observable"
WARNING - root - Added new config entry: "env_make_kwargs.max_steps"
WARNING - root - Added new config entry: "env_make_kwargs.noise_insertion"
WARNING - root - Added new config entry: "env_make_kwargs.rollout_path"
WARNING - train_adversarial - No observers have been added to this run
INFO - train_adversarial - Running command 'airl'
INFO - train_adversarial - Started
INFO - imitation.scripts.common.common - Logging to output/airl/soContSpaces-v1/20230712_155856_d19f2a

algo_cls<class 'imitation.algorithms.adversarial.airl.AIRL'>

/home/eshaan/Ehsan/Visual-IRL/imitation/src/imitation/util/sacred.py:85: RuntimeWarning: Couldn't find sacred directory.
  warnings.warn(RuntimeWarning("Couldn't find sacred directory."))
INFO - imitation.scripts.common.rl - RL algorithm: <class 'stable_baselines3.ppo.ppo.PPO'>
INFO - imitation.scripts.common.rl - Policy network summary:
 FeedForward32Policy(
  (features_extractor): NormalizeFeaturesExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (normalize): RunningNorm()
  )
  (mlp_extractor): MlpExtractor(
    (shared_net): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): Tanh()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): Tanh()
    )
    (policy_net): Sequential()
    (value_net): Sequential()
  )
  (action_net): Linear(in_features=32, out_features=2, bias=True)
  (value_net): Linear(in_features=32, out_features=1, bias=True)
)
INFO - imitation.scripts.train_adversarial - Using '<class 'imitation.algorithms.adversarial.airl.AIRL'>' algorithm
Running with `allow_variable_horizon` set to True. Some algorithms are biased towards shorter or longer episodes, which may significantly confound results. Additionally, even unbiased algorithms can exploit the information leak from the termination condition, producing spuriously high performance. See https://imitation.readthedocs.io/en/latest/guide/variable_horizon.html for more information.
round:   0%|          | 0/156 [00:00<?, ?it/s]-------------------------------------
| raw/                        |     |
|    gen/time/fps             | 4   |
|    gen/time/iterations      | 1   |
|    gen/time/time_elapsed    | 27  |
|    gen/time/total_timesteps | 128 |
-------------------------------------
Gibbs sampled averaged discimantor logits  tensor([ 2.0480,  2.0086,  2.0491,  2.1192,  2.0416,  1.9113,  2.1105,  1.8729,
         1.9714,  1.9367,  1.9868,  1.9523,  2.0791,  2.1264,  1.9897,  2.1438,
         2.1201,  2.1820,  1.8907,  2.2318,  1.9220,  1.7380,  1.9001,  1.9939,
         1.4581,  1.9825,  2.1472,  2.1192,  2.0658,  1.9367,  2.2281, -0.3539,
         1.9947,  2.0206,  2.2690,  2.2501,  2.2118,  2.8711,  2.0006,  2.2005,
         2.3387,  2.3177,  2.5204,  2.3192,  2.4476,  2.2778,  2.7266,  2.6883,
         2.9472,  2.5740,  2.3985,  3.0030,  2.4716,  2.6883,  2.4924,  2.7405,
         2.5493,  2.3192,  2.5503,  2.2905,  2.7675,  2.2118,  2.5576,  2.0006],
       grad_fn=<DivBackward0>)
 normed_delta_avg_disc_logits converged in 1.68
--------------------------------------------------
| raw/                                |          |
|    disc/disc_acc                    | 0.484    |
|    disc/disc_acc_expert             | 0.969    |
|    disc/disc_acc_gen                | 0        |
|    disc/disc_entropy                | 0.328    |
|    disc/disc_loss                   | 1.34     |
|    disc/disc_proportion_expert_pred | 0.984    |
|    disc/disc_proportion_expert_true | 0.5      |
|    disc/global_step                 | 1        |
|    disc/n_expert                    | 32       |
|    disc/n_generated                 | 32       |
--------------------------------------------------
Gibbs sampled averaged discimantor logits  tensor([2.0052, 1.9713, 2.0418, 1.9905, 2.0168, 1.9701, 1.9861, 2.0323, 2.0144,
        1.9896, 1.8769, 1.9716, 1.9830, 2.0586, 1.9878, 2.0510, 2.0370, 1.9573,
        2.0007, 1.9775, 2.1018, 2.1266, 1.8376, 2.0241, 1.9763, 2.0065, 1.9936,
        1.8691, 1.8271, 1.9223, 1.9608, 1.9199, 2.4474, 2.5442, 2.1782, 2.0063,
        2.8172, 2.1557, 2.3095, 3.0448, 1.9711, 2.7727, 2.9667, 2.1660, 2.9323,
        2.7046, 2.8409, 2.7005, 2.1782, 2.4276, 2.4047, 2.5250, 2.9229, 2.0074,
        2.4037, 1.8310, 2.9738, 2.5250, 2.6090, 2.4047, 2.5250, 2.7113, 2.4446,
        2.7824], grad_fn=<DivBackward0>)
 normed_delta_avg_disc_logits converged in 1.74
--------------------------------------------------
| raw/                                |          |
|    disc/disc_acc                    | 0.5      |
|    disc/disc_acc_expert             | 1        |
|    disc/disc_acc_gen                | 0        |
|    disc/disc_entropy                | 0.32     |
|    disc/disc_loss                   | 1.36     |
|    disc/disc_proportion_expert_pred | 1        |
|    disc/disc_proportion_expert_true | 0.5      |
|    disc/global_step                 | 1        |
|    disc/n_expert                    | 32       |
|    disc/n_generated                 | 32       |
--------------------------------------------------
Gibbs sampled averaged discimantor logits  tensor([2.1310, 2.1213, 1.9997, 2.0527, 2.0656, 2.0019, 1.9914, 2.0960, 1.8084,
        1.9456, 1.9296, 2.0224, 1.9721, 1.9214, 1.8916, 1.9936, 2.0026, 1.9851,
        2.1376, 2.0770, 2.0864, 2.0973, 1.9976, 1.9220, 1.8178, 1.1053, 1.7462,
        1.9199, 1.9915, 2.0113, 2.0452, 1.9553, 2.6939, 2.4324, 2.2182, 3.0193,
        2.9071, 2.4903, 2.6843, 2.2118, 2.8943, 2.3792, 2.0644, 2.1276, 3.0594,
        2.0008, 2.1810, 2.1733, 2.2658, 2.3657, 2.3139, 2.1535, 2.1117, 2.7526,
        2.5981, 2.0907, 2.0907, 2.2131, 1.9882, 3.0193, 2.2658, 2.2675, 2.4142,
        2.2480], grad_fn=<DivBackward0>)
 normed_delta_avg_disc_logits converged in 1.7
--------------------------------------------------
| raw/                                |          |
|    disc/disc_acc                    | 0.5      |
|    disc/disc_acc_expert             | 1        |
|    disc/disc_acc_gen                | 0        |
|    disc/disc_entropy                | 0.332    |
|    disc/disc_loss                   | 1.31     |
|    disc/disc_proportion_expert_pred | 1        |
|    disc/disc_proportion_expert_true | 0.5      |
|    disc/global_step                 | 1        |
|    disc/n_expert                    | 32       |
|    disc/n_generated                 | 32       |
--------------------------------------------------
Gibbs sampled averaged discimantor logits  tensor([1.9716, 1.9280, 2.0041, 2.1055, 1.9878, 1.8581, 1.8330, 1.9013, 2.0596,
        1.9852, 2.1185, 2.0214, 2.0020, 2.0478, 1.9515, 1.8627, 2.0129, 2.1003,
        2.0183, 1.8727, 2.0068, 1.8341, 1.8259, 2.0035, 1.9688, 1.8764, 1.9526,
        1.9905, 2.0494, 1.9490, 1.9614, 1.9647, 1.9705, 2.7404, 2.7478, 2.1497,
        2.2454, 2.2996, 2.4196, 2.7404, 2.1565, 2.5310, 2.4938, 2.5774, 2.4900,
        2.4302, 2.7354, 1.9878, 1.9705, 2.1142, 2.4967, 2.0765, 1.9830, 2.1019,
        2.5323, 2.1698, 2.3217, 2.5826, 2.7354, 2.5813, 2.8054, 2.5310, 2.9949,
        2.0494], grad_fn=<DivBackward0>)
 normed_delta_avg_disc_logits converged in 1.67
--------------------------------------------------
| raw/                                |          |
|    disc/disc_acc                    | 0.5      |
|    disc/disc_acc_expert             | 1        |
|    disc/disc_acc_gen                | 0        |
|    disc/disc_entropy                | 0.331    |
|    disc/disc_loss                   | 1.31     |
|    disc/disc_proportion_expert_pred | 1        |
|    disc/disc_proportion_expert_true | 0.5      |
|    disc/global_step                 | 1        |
|    disc/n_expert                    | 32       |
|    disc/n_generated                 | 32       |
--------------------------------------------------
--------------------------------------------------
| mean/                               |          |
|    disc/disc_acc                    | 0.496    |
|    disc/disc_acc_expert             | 0.992    |
|    disc/disc_acc_gen                | 0        |
|    disc/disc_entropy                | 0.328    |
|    disc/disc_loss                   | 1.33     |
|    disc/disc_proportion_expert_pred | 0.996    |
|    disc/disc_proportion_expert_true | 0.5      |
|    disc/global_step                 | 1        |
|    disc/n_expert                    | 32       |
|    disc/n_generated                 | 32       |
|    gen/time/fps                     | 4        |
|    gen/time/iterations              | 1        |
|    gen/time/time_elapsed            | 27       |
|    gen/time/total_timesteps         | 128      |
|    gen/train/approx_kl              | 0.000895 |
|    gen/train/clip_fraction          | 0.00234  |
|    gen/train/clip_range             | 0.2      |
|    gen/train/entropy_loss           | -2.84    |
|    gen/train/explained_variance     | 0.00453  |
|    gen/train/learning_rate          | 0.0003   |
|    gen/train/loss                   | 91.6     |
|    gen/train/n_updates              | 10       |
|    gen/train/policy_gradient_loss   | -0.00639 |
|    gen/train/std                    | 1        |
|    gen/train/value_loss             | 181      |
--------------------------------------------------
/home/eshaan/Ehsan/Visual-IRL/imitation/src/imitation/algorithms/adversarial/common.py:631: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  GT_traj = np.array([[init_obs[0],None]])
/home/eshaan/Ehsan/Visual-IRL/imitation/src/imitation/algorithms/adversarial/common.py:640: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  GT_traj = np.vstack((GT_traj,np.array([ns, -1])))
/home/eshaan/Ehsan/Visual-IRL/imitation/src/imitation/algorithms/adversarial/common.py:688: RuntimeWarning: covariance is not positive-semidefinite.
  s = np.random.multivariate_normal(mean_Gs_s_g_t, cov_Gs_s_g_t, (1))[0]
round:   1%|          | 1/156 [07:15<18:45:07, 435.53s/it]-----------------------------------------------------
| raw/                              |               |
|    gen/time/fps                   | 4             |
|    gen/time/iterations            | 1             |
|    gen/time/time_elapsed          | 27            |
|    gen/time/total_timesteps       | 256           |
|    gen/train/approx_kl            | 0.00089501636 |
|    gen/train/clip_fraction        | 0.00234       |
|    gen/train/clip_range           | 0.2           |
|    gen/train/entropy_loss         | -2.84         |
|    gen/train/explained_variance   | 0.00453       |
|    gen/train/learning_rate        | 0.0003        |
|    gen/train/loss                 | 91.6          |
|    gen/train/n_updates            | 10            |
|    gen/train/policy_gradient_loss | -0.00639      |
|    gen/train/std                  | 1             |
|    gen/train/value_loss           | 181           |
-----------------------------------------------------
